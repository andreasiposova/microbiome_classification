{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold, train_test_split\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from preprocess_data import preprocess\n",
    "from load_data import load_data, load_files, load_yang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fudan_filepath = 'data/Yang_PRJNA763023/Yang_PRJNA763023_SE/parsed/normalized_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsv_files(folder):\n",
    "    # Initialize an empty dictionary to store the variables\n",
    "    var_dict = {}\n",
    "    \n",
    "    # Iterate over the files in the folder\n",
    "    for file in os.listdir(folder):\n",
    "        # Only consider files with the '.tsv' extension\n",
    "        if file.endswith('.tsv'):\n",
    "            # Load the data into a pandas DataFrame\n",
    "            df = pd.read_csv(os.path.join(folder, file), sep='\\t') # skiprows=1\n",
    "            if len(df.columns) == 1:\n",
    "                df = pd.read_csv(os.path.join(folder, file), sep='\\t', skiprows=1)\n",
    "                df = df.transpose()\n",
    "                df.columns = df.iloc[0]\n",
    "                df.drop(index=df.index[0], axis=0, inplace=True)\n",
    "                #print(file)\n",
    "            else:\n",
    "                #print(file)\n",
    "                columnNames = df.columns.tolist()\n",
    "                firstColName = columnNames[0]\n",
    "                df.set_index(firstColName, inplace=True)\n",
    "            # Get the file name without the '.tsv' extension\n",
    "            name = os.path.splitext(file)[0]\n",
    "            \n",
    "            # Assign the DataFrame to a variable with the file name\n",
    "            globals()[name] = df\n",
    "            \n",
    "            # Add the variable to the dictionary with the file name as the key\n",
    "            var_dict[name] = globals()[name]\n",
    "    \n",
    "    # Return the dictionary of variables\n",
    "    return var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "\n",
    "    data_files = load_tsv_files(filepath)\n",
    "\n",
    "    for key, value in data_files.items():\n",
    "        globals()[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(fudan_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_vars = globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list((\"pielou_e_diversity\", \"simpson_diversity\", \"phylum_relative\", \"observed_otus_diversity\", \"family_relative\",\n",
    "\"class_relative\", \"fb_ratio\", \"enterotype\", \"genus_relative\", \"species_relative\", \"shannon_diversity\", \"domain_relative\",\n",
    "\"order_relative\", \"simpson_e_diversity\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metadata(filepath):\n",
    "    data = pd.read_csv(filepath, sep=\",\", usecols=[\"Run\", \"disease_stat\"])\n",
    "    data.set_index('Run', inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yang_metadata = load_metadata(\"data/Yang_PRJNA763023/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pielou_e_diversity\n",
      "0.8789763060925544\n",
      "(array([0, 1]), array([112, 107]))\n",
      "The results for pielou_e_diversity are: accuracy 0.4840182648401826, conf.mat.:[[59 53]\n",
      " [60 47]], roc auc:0.48301902536715624, precision, recall, f1:(0.48289915966386554, 0.48301902536715624, 0.48246439550787373, None)\n",
      "simpson_diversity\n",
      "0.98669128\n",
      "(array([0, 1]), array([112, 107]))\n",
      "The results for simpson_diversity are: accuracy 0.5251141552511416, conf.mat.:[[59 53]\n",
      " [51 56]], roc auc:0.5250751001335114, precision, recall, f1:(0.5250625521267723, 0.5250751001335113, 0.525025025025025, None)\n",
      "phylum_relative\n",
      "0.002\n",
      "0.0132\n",
      "0.8686\n",
      "0.8804\n",
      "0.0002\n",
      "0.0002\n",
      "0.0068\n",
      "0.0042\n",
      "0.0004\n",
      "0.2662\n",
      "0.0004\n",
      "0.0004\n",
      "0.005\n",
      "0.0008\n",
      "0.068\n",
      "0.0002\n",
      "0.9878\n",
      "0.657\n",
      "0.0024\n",
      "0.0004\n",
      "0.001\n",
      "0.0\n",
      "0.0192\n",
      "0.0002\n",
      "0.9886\n",
      "0.0\n",
      "0.0024\n",
      "0.0758\n",
      "0.0002\n",
      "0.568\n",
      "0.022000000000000002\n",
      "0.1728\n",
      "(array([0, 1]), array([112, 107]))\n",
      "The results for phylum_relative are: accuracy 0.5981735159817352, conf.mat.:[[76 36]\n",
      " [52 55]], roc auc:0.5962950600801069, precision, recall, f1:(0.5990728021978022, 0.5962950600801068, 0.5944444444444444, None)\n",
      "observed_otus_diversity\n",
      "367\n",
      "(array([0, 1]), array([112, 107]))\n",
      "The results for observed_otus_diversity are: accuracy 0.54337899543379, conf.mat.:[[63 49]\n",
      " [51 56]], roc auc:0.5429322429906542, precision, recall, f1:(0.5429824561403509, 0.5429322429906542, 0.542912005343129, None)\n",
      "family_relative\n",
      "0.002\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0002\n",
      "0.0\n",
      "0.0002\n",
      "0.0\n",
      "0.0\n",
      "0.0076\n",
      "0.0002\n",
      "0.0006\n",
      "0.0004\n",
      "0.0052\n",
      "0.0002\n",
      "0.0004\n",
      "0.0086\n",
      "0.0036\n",
      "0.018000000000000002\n",
      "0.8528\n",
      "0.0358\n",
      "0.002\n",
      "0.002\n",
      "0.0012\n",
      "0.0008\n",
      "0.0032\n",
      "0.0002\n",
      "0.0002\n",
      "0.0\n",
      "0.0008\n",
      "0.0006\n",
      "0.0014\n",
      "0.0038\n",
      "0.0124\n",
      "0.0326\n",
      "0.0004\n",
      "0.0014\n",
      "0.0242\n",
      "0.0002\n",
      "0.0292\n",
      "0.3176\n",
      "0.006\n",
      "0.2114\n",
      "0.0026\n",
      "0.0004\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0002\n",
      "0.0002\n",
      "0.82\n",
      "0.0004\n",
      "0.1476\n",
      "0.0004\n",
      "0.0444\n",
      "0.0416\n",
      "0.2192\n",
      "0.78\n",
      "0.3358\n",
      "0.5082\n",
      "0.085\n",
      "0.0724\n",
      "0.0016\n",
      "0.0002\n",
      "0.0006\n",
      "0.0386\n",
      "0.0002\n",
      "0.001\n",
      "0.0002\n",
      "0.0184\n",
      "0.0002\n",
      "0.0002\n",
      "0.0002\n",
      "0.0068\n",
      "0.0004\n",
      "0.0\n",
      "0.0042\n",
      "0.0002\n",
      "0.0002\n",
      "0.0004\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0004\n",
      "0.2662\n",
      "0.0002\n",
      "0.0006\n",
      "0.0804\n",
      "0.0\n",
      "0.0004\n",
      "0.0004\n",
      "0.005\n",
      "0.0002\n",
      "0.0008\n",
      "0.068\n",
      "0.001\n",
      "0.0002\n",
      "0.0\n",
      "0.0002\n",
      "0.0\n",
      "0.0\n",
      "0.0012\n",
      "0.0046\n",
      "0.3106\n",
      "0.3372\n",
      "0.0\n",
      "0.0\n",
      "0.0006\n",
      "0.5322\n",
      "0.2688\n",
      "0.0006\n",
      "0.0006\n",
      "0.0018\n",
      "0.0066\n",
      "0.444\n",
      "0.8098\n",
      "0.3458\n",
      "0.0004\n",
      "0.0012\n",
      "0.628\n",
      "0.0084\n",
      "0.0516\n",
      "0.0018\n",
      "0.0002\n",
      "0.1218\n",
      "0.2494\n",
      "0.011000000000000001\n",
      "0.0002\n",
      "0.0036\n",
      "0.0796\n",
      "0.2566\n",
      "0.005\n",
      "0.0006\n",
      "0.5812\n",
      "0.0028\n",
      "0.0002\n",
      "0.0194\n",
      "0.0022\n",
      "0.7692\n",
      "0.0002\n",
      "0.1028\n",
      "0.1184\n",
      "0.0006\n",
      "0.2142\n",
      "0.6814\n",
      "0.0108\n",
      "0.0728\n",
      "0.0086\n",
      "0.534\n",
      "0.1308\n",
      "0.006\n",
      "0.0298\n",
      "0.3758\n",
      "0.221\n",
      "0.0002\n",
      "0.0048\n",
      "0.003\n",
      "0.1606\n",
      "0.0002\n",
      "0.0008\n",
      "0.0002\n",
      "0.525\n",
      "0.6782\n",
      "0.578\n",
      "0.0326\n",
      "0.0008\n",
      "0.0172\n",
      "0.657\n",
      "0.0184\n",
      "0.0024\n",
      "0.0002\n",
      "0.0004\n",
      "0.001\n",
      "0.0\n",
      "0.0\n",
      "0.0192\n",
      "0.0\n",
      "0.0002\n",
      "0.04\n",
      "0.0012\n",
      "0.1492\n",
      "0.011000000000000001\n",
      "0.0\n",
      "0.0002\n",
      "0.0686\n",
      "0.0254\n",
      "0.0002\n",
      "0.0054\n",
      "0.0002\n",
      "0.1032\n",
      "0.0004\n",
      "0.0014\n",
      "0.0006\n",
      "0.001\n",
      "0.0088\n",
      "0.0002\n",
      "0.111\n",
      "0.0002\n",
      "0.0018\n",
      "0.0064\n",
      "0.0032\n",
      "0.0046\n",
      "0.0006\n",
      "0.0002\n",
      "0.0036\n",
      "0.0342\n",
      "0.3766\n",
      "0.0004\n",
      "0.0008\n",
      "0.0084\n",
      "0.0004\n",
      "0.0204\n",
      "0.0278\n",
      "0.0002\n",
      "0.2292\n",
      "0.0086\n",
      "0.0044\n",
      "0.0002\n",
      "0.9868\n",
      "0.0016\n",
      "0.1752\n",
      "0.0042\n",
      "0.0684\n",
      "0.0\n",
      "0.0024\n",
      "0.0008\n",
      "0.1358\n",
      "0.0212\n",
      "0.3762\n",
      "0.0\n",
      "0.0002\n",
      "0.0022\n",
      "0.0004\n",
      "0.0076\n",
      "0.0012\n",
      "0.0\n",
      "0.0024\n",
      "0.0758\n",
      "0.0002\n",
      "0.0014\n",
      "0.0008\n",
      "0.0\n",
      "0.568\n",
      "0.0002\n",
      "0.022000000000000002\n",
      "0.1728\n",
      "(array([0, 1]), array([112, 107]))\n",
      "The results for family_relative are: accuracy 0.7168949771689498, conf.mat.:[[82 30]\n",
      " [32 75]], roc auc:0.7165387182910548, precision, recall, f1:(0.7167919799498748, 0.7165387182910548, 0.71660544331274, None)\n",
      "class_relative\n",
      "0.002\n",
      "0.0002\n",
      "0.0076\n",
      "0.0006\n",
      "0.0052\n",
      "0.0086\n",
      "0.8528\n",
      "0.3184\n",
      "0.0\n",
      "0.0\n",
      "0.0002\n",
      "0.0002\n",
      "0.8804\n",
      "0.0002\n",
      "0.0002\n",
      "0.0068\n",
      "0.0\n",
      "0.0042\n",
      "0.0004\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0004\n",
      "0.2662\n",
      "0.0804\n",
      "0.0004\n",
      "0.0004\n",
      "0.005\n",
      "0.0008\n",
      "0.068\n",
      "0.0002\n",
      "0.0\n",
      "0.0002\n",
      "0.0\n",
      "0.0012\n",
      "0.9396\n",
      "0.9298\n",
      "0.0002\n",
      "0.0008\n",
      "0.0002\n",
      "0.7296\n",
      "0.0172\n",
      "0.657\n",
      "0.0024\n",
      "0.0002\n",
      "0.0004\n",
      "0.001\n",
      "0.0\n",
      "0.0\n",
      "0.0192\n",
      "0.0\n",
      "0.0002\n",
      "0.272\n",
      "0.9886\n",
      "0.0\n",
      "0.0024\n",
      "0.0758\n",
      "0.0002\n",
      "0.0014\n",
      "0.568\n",
      "0.022000000000000002\n",
      "0.1728\n",
      "(array([0, 1]), array([112, 107]))\n",
      "The results for class_relative are: accuracy 0.6210045662100456, conf.mat.:[[82 30]\n",
      " [53 54]], roc auc:0.6184078771695594, precision, recall, f1:(0.6251322751322752, 0.6184078771695594, 0.6147063187570214, None)\n",
      "fb_ratio\n",
      "4939.0\n",
      "              fb_ratio\n",
      "Unnamed: 0            \n",
      "SRR15884562  60.129032\n",
      "SRR15884810   6.474153\n",
      "SRR15884570   4.831395\n",
      "SRR15884266   1.291121\n",
      "SRR15884700  50.950617\n",
      "...                ...\n",
      "SRR15884572   1.249315\n",
      "SRR15884404  14.021605\n",
      "SRR15884252  47.406977\n",
      "SRR15884494  89.479167\n",
      "SRR15884923  81.045455\n",
      "\n",
      "[508 rows x 1 columns]\n",
      "(array([0, 1]), array([112, 107]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [219, 211]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-420447adee0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mnu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mp_r_f1_support\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    332\u001b[0m         raise ValueError(\n\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [219, 211]"
     ]
    }
   ],
   "source": [
    "for file_name in file_names:\n",
    "    dataset = globals()[file_name]\n",
    "    print(file_name)\n",
    "    data = dataset.join(yang_metadata)\n",
    "    X = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "    le.fit(y_train)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    for col in X_train.columns:\n",
    "        #find max value of column\n",
    "        max_value_train = np.nanmax(X_train[col][X_train[col] != np.inf])\n",
    "        #max_value_train = np.nanmax(X_train['my_column'][X_train['my_column'] != np.inf])\n",
    "        print(max_value_train)\n",
    "        #replace inf and -inf in column with max value of column \n",
    "        X_train[col].replace([np.inf, -np.inf], max_value_train, inplace=True)\n",
    "        #drop the inf values from the test set\n",
    "        X_test = X_test.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        #get the respective y when we drop observations from the test set\n",
    "        \n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators= 100, max_depth=50, random_state=1234, class_weight={0: 1})\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    nu = np.unique(y_test, return_counts=True)\n",
    "    print(nu)\n",
    "    p_r_f1_support = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print('The results for ' + file_name + \" are: accuracy \" + str(acc) + \", conf.mat.:\" + str(cm) + \", roc auc:\" + str(roc_auc) + \", precision, recall, f1:\" + str(p_r_f1_support))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.any(np.isnan(fb_ratio))\n",
    "#np.all(np.isfinite(fb_ratio))\n",
    "#fb_ratio = fb_ratio.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "#fb_ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
